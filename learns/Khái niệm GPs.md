# 1. KhÃ¡i niá»‡m cÆ¡ báº£n vá» Gaussian Processes

## 1.1 Gaussian lÃ  gÃ¬?

- Báº¡n Ä‘Ã£ biáº¿t **Gaussian distribution** (phÃ¢n phá»‘i chuáº©n) rá»“i, Ä‘Ãºng khÃ´ng? 
- NÃ³ lÃ  dáº¡ng phÃ¢n phá»‘i chuÃ´ng quen thuá»™c, Ä‘áº·c trÆ°ng bá»Ÿi:
  - **Mean (Î¼)**: giÃ¡ trá»‹ trung bÃ¬nh
  - **Variance (ÏƒÂ²)**: Ä‘á»™ phÃ¢n tÃ¡n

CÃ´ng thá»©c phÃ¢n phá»‘i chuáº©n 1 chiá»u:

$
p(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right)
$

---

## 1.2 Gaussian Ä‘a chiá»u (Multivariate Gaussian)

- Khi má»Ÿ rá»™ng Gaussian ra nhiá»u chiá»u (n chiá»u), ta cÃ³ **Multivariate Gaussian distribution**.
- Thay vÃ¬ chá»‰ mean vÃ  variance, bÃ¢y giá» cáº§n:
  - **Mean vector** $ \mu \in \mathbb{R}^n $
  - **Covariance matrix** $ \Sigma \in \mathbb{R}^{n \times n} $

CÃ´ng thá»©c:

$
p(\mathbf{x}) = \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp\left( -\frac{1}{2}(\mathbf{x} - \mu)^T \Sigma^{-1} (\mathbf{x} - \mu) \right)
$

---
## 1.3 Gaussian Process lÃ  gÃ¬?

**Gaussian Process** (GP) lÃ  má»™t *khÃ¡i niá»‡m tá»•ng quÃ¡t hÃ³a* cá»§a phÃ¢n phá»‘i Gaussian Ä‘a chiá»u cho... **vÃ´ háº¡n chiá»u**.

### Äá»‹nh nghÄ©a Ä‘Æ¡n giáº£n:
> **Gaussian Process lÃ  má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn toÃ n bá»™ cÃ¡c hÃ m sá»‘.**  
> NghÄ©a lÃ , báº¥t ká»³ táº­p con há»¯u háº¡n nÃ o cá»§a cÃ¡c Ä‘iá»ƒm Ä‘áº§u vÃ o, Ä‘áº§u ra tÆ°Æ¡ng á»©ng cá»§a chÃºng sáº½ cÃ³ phÃ¢n phá»‘i Gaussian.

### HÃ¬nh dung:
- Thay vÃ¬ nÃ³i "vector nÃ y cÃ³ phÃ¢n phá»‘i Gaussian", ta nÃ³i "hÃ m sá»‘ nÃ y cÃ³ phÃ¢n phá»‘i Gaussian."
- Má»™t GP Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi:
  - **Mean function** $ m(x) $: mean cá»§a output táº¡i má»—i Ä‘iá»ƒm $ x $.
  - **Covariance function** $ k(x, x') $: Ä‘á»™ liÃªn há»‡ (covariance) giá»¯a output táº¡i $ x $ vÃ  $ x' $.

CÃ¡ch viáº¿t GP:

$
f(x) \sim \mathcal{GP}(m(x), k(x, x'))
$

---
## 1.4 VÃ¬ sao Gaussian Process máº¡nh?

- **Bayesian by nature**: LuÃ´n cÃ³ phÃ¢n phá»‘i xÃ¡c suáº¥t cho má»i dá»± Ä‘oÃ¡n, thá»ƒ hiá»‡n Ä‘Æ°á»£c **sá»± khÃ´ng cháº¯c cháº¯n (uncertainty)**.
- **KhÃ´ng cáº§n chá»‰ rÃµ dáº¡ng hÃ m sá»‘**: Thay vÃ¬ giáº£ Ä‘á»‹nh mÃ´ hÃ¬nh lÃ  linear/quadratic/... GP tá»± tÃ¬m hÃ m tá»‘i Æ°u qua dá»¯ liá»‡u.
- **Linh hoáº¡t**: CÃ³ thá»ƒ Ä‘iá»u chá»‰nh báº±ng kernel Ä‘á»ƒ phÃ¹ há»£p vá»›i dá»¯ liá»‡u phá»©c táº¡p.

---
## 1.5 áº¢nh minh há»a trá»±c quan

VÃ­ dá»¥, náº¿u báº¡n chá»n GP vá»›i mean function báº±ng 0 vÃ  kernel RBF:

- TrÆ°á»›c khi nhÃ¬n dá»¯ liá»‡u, cÃ¡c hÃ m máº«u tá»« GP sáº½ nhÆ° tháº¿ nÃ y:

![Gaussian Process prior](https://upload.wikimedia.org/wikipedia/commons/6/6b/Gaussian_Process_Prior.png)

- Sau khi quan sÃ¡t má»™t vÃ i Ä‘iá»ƒm dá»¯ liá»‡u, GP sáº½ update thÃ nh posterior:

![Gaussian Process posterior](https://upload.wikimedia.org/wikipedia/commons/0/0c/Gaussian_Process_Posterior.png)

(Báº¡n tháº¥y khÃ´ng, Ä‘Æ°á»ng dá»± Ä‘oÃ¡n Ä‘i qua cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u vá»›i vÃ¹ng "confidence" háº¹p láº¡i.)

---

# ğŸ¯ Káº¿t luáº­n má»¥c 1
- GP = PhÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn táº­p cÃ¡c hÃ m sá»‘.
- XÃ¡c Ä‘á»‹nh báº±ng mean function vÃ  kernel (covariance function).
- Má»i táº­p con há»¯u háº¡n cÃ¡c Ä‘iá»ƒm Ä‘á»u cÃ³ phÃ¢n phá»‘i Gaussian.
- Máº¡nh máº½ á»Ÿ chá»— nÃ³ dá»± Ä‘oÃ¡n kÃ¨m theo Ä‘á»™ khÃ´ng cháº¯c cháº¯n (uncertainty).

---

Ráº¥t tuyá»‡t, mÃ¬nh sáº½ dáº«n báº¡n vÃ o **Má»¥c 2: ToÃ¡n há»c ná»n táº£ng cá»§a Gaussian Processes** nhÃ©.  
Pháº§n nÃ y mÃ¬nh sáº½ trÃ¬nh bÃ y cháº­m rÃ£i, dá»… hiá»ƒu, cÃ³ vÃ­ dá»¥ minh há»a.

---

# 2. ToÃ¡n há»c ná»n táº£ng cá»§a Gaussian Processes

## 2.1 GP Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi gÃ¬?

NhÆ° Ä‘Ã£ nÃ³i á»Ÿ má»¥c 1, má»™t GP hoÃ n toÃ n xÃ¡c Ä‘á»‹nh bá»Ÿi:
- **HÃ m trung bÃ¬nh** $ m(x) $
- **HÃ m hiá»‡p phÆ°Æ¡ng sai** (kernel) $ k(x, x') $

CÃ´ng thá»©c:

$
f(x) \sim \mathcal{GP}(m(x), k(x, x'))
$

Trong Ä‘Ã³:
- $ m(x) = \mathbb{E}[f(x)] $
- $ k(x, x') = \mathbb{E}\left[(f(x) - m(x))(f(x') - m(x'))\right] $

ğŸ‘‰ *HÃ m mean* cho ta biáº¿t ká»³ vá»ng táº¡i má»—i Ä‘iá»ƒm, *hÃ m kernel* cho ta biáº¿t má»©c Ä‘á»™ liÃªn quan giá»¯a cÃ¡c Ä‘iá»ƒm.

---

## 2.2 Dá»± Ä‘oÃ¡n vá»›i Gaussian Process (Posterior Prediction)

Giáº£ sá»­ báº¡n Ä‘Ã£ cÃ³:
- Dá»¯ liá»‡u huáº¥n luyá»‡n: $ X = \{x_1, x_2, ..., x_n\} $, nhÃ£n $ \mathbf{y} = \{y_1, ..., y_n\} $
- Báº¡n muá»‘n dá»± Ä‘oÃ¡n output táº¡i Ä‘iá»ƒm má»›i $ x_* $.

**Quy trÃ¬nh:**

1. TÃ­nh **ma tráº­n kernel**:
   - $ K(X, X) $: giá»¯a cÃ¡c Ä‘iá»ƒm training vá»›i nhau (size $ n \times n $)
   - $ K(X, x_*) $: giá»¯a cÃ¡c Ä‘iá»ƒm training vÃ  Ä‘iá»ƒm cáº§n dá»± Ä‘oÃ¡n (size $ n \times 1 $)
   - $ K(x_*, x_*) $: giá»¯a Ä‘iá»ƒm cáº§n dá»± Ä‘oÃ¡n vá»›i chÃ­nh nÃ³ (scalar)

2. Dá»± Ä‘oÃ¡n mean vÃ  variance:
   - Mean:

$
\mu_* = K(X, x_*)^T K(X, X)^{-1} \mathbf{y}
$

   - Variance:

$
\sigma_*^2 = K(x_*, x_*) - K(X, x_*)^T K(X, X)^{-1} K(X, x_*)
$

ğŸ‘‰ Ã nghÄ©a:
- $\mu_*$ lÃ  giÃ¡ trá»‹ dá»± Ä‘oÃ¡n trung bÃ¬nh táº¡i $ x_* $.
- $\sigma_*^2$ lÃ  má»©c Ä‘á»™ khÃ´ng cháº¯c cháº¯n táº¡i $ x_* $ (khoáº£ng tin cáº­y).

---
## 2.3 CÃ¡c Kernel phá»• biáº¿n trong GP

HÃ m kernel (hay cÃ²n gá»i lÃ  *covariance function*) quyáº¿t Ä‘á»‹nh tÃ­nh cháº¥t cá»§a hÃ m sá»‘ mÃ  GP mÃ´ hÃ¬nh hÃ³a.

Má»™t sá»‘ kernel phá»• biáº¿n:

| TÃªn | CÃ´ng thá»©c | Äáº·c Ä‘iá»ƒm |
|:---|:---|:---|
| RBF (Radial Basis Function) / Squared Exponential | $ k(x,x') = \sigma_f^2 \exp\left(-\frac{(x-x')^2}{2\ell^2}\right) $ | HÃ m ráº¥t mÆ°á»£t, trÆ¡n |
| Matern | Phá»©c táº¡p hÆ¡n, cÃ³ thÃªm tham sá»‘ Ä‘iá»u khiá»ƒn Ä‘á»™ trÆ¡n | Äiá»u chá»‰nh Ä‘á»™ mÆ°á»£t |
| Linear Kernel | $ k(x,x') = \sigma_b^2 + \sigma_v^2 x x' $ | MÃ´ hÃ¬nh hÃ³a quan há»‡ tuyáº¿n tÃ­nh |
| Periodic Kernel | CÃ´ng thá»©c liÃªn quan Ä‘áº¿n hÃ m sin | Báº¯t tÃ­nh chu ká»³ |

**Trong thá»±c táº¿:** thÆ°á»ng dÃ¹ng RBF hoáº·c Matern kernel.

---

## 2.4 Gaussian Noise trong GP

Trong thá»±c táº¿, dá»¯ liá»‡u cÃ³ nhiá»…u.  
Ta mÃ´ hÃ¬nh hÃ³a Ä‘iá»u nÃ y báº±ng cÃ¡ch cá»™ng thÃªm nhiá»…u Gaussian vÃ o kernel:

$
K(X,X) \leftarrow K(X,X) + \sigma_n^2 I
$

Trong Ä‘Ã³:
- $ \sigma_n^2 $ lÃ  variance cá»§a noise
- $ I $ lÃ  ma tráº­n Ä‘Æ¡n vá»‹

ğŸ‘‰ Äiá»u nÃ y lÃ m GP trá»Ÿ nÃªn "chá»‹u Ä‘á»±ng" noise tá»‘t hÆ¡n!

---

# 2.5 Minh há»a báº±ng vÃ­ dá»¥ cá»¥ thá»ƒ

Giáº£ sá»­:
- Báº¡n cÃ³ 3 Ä‘iá»ƒm training: $ (0,1), (1,2), (2,0.5) $
- Báº¡n muá»‘n dá»± Ä‘oÃ¡n táº¡i $ x_* = 1.5 $
- DÃ¹ng RBF kernel vá»›i $ \sigma_f = 1 $, $ \ell = 1 $

**CÃ¡c bÆ°á»›c:**
- TÃ­nh ma tráº­n kernel $ K(X, X) $
- TÃ­nh vector kernel $ K(X, x_*) $
- Ãp dá»¥ng cÃ´ng thá»©c mean, variance bÃªn trÃªn.

(Khi cáº§n mÃ¬nh cÃ³ thá»ƒ Ä‘i tÃ­nh cá»¥ thá»ƒ luÃ´n nhÃ©.)

---

# ğŸ¯ TÃ³m láº¡i Má»¥c 2:

- Gaussian Process prediction dá»±a trÃªn tÃ­nh toÃ¡n tá»« ma tráº­n kernel.
- Dá»± Ä‘oÃ¡n tráº£ vá» **mean** vÃ  **uncertainty** (variance).
- Kernel quyáº¿t Ä‘á»‹nh tÃ­nh cháº¥t cá»§a hÃ m sá»‘ (trÆ¡n tru, gáº¥p khÃºc, tuáº§n hoÃ n...).
- Noise Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a báº±ng cÃ¡ch cá»™ng $ \sigma_n^2 I $ vÃ o kernel.

---

Tuyá»‡t vá»i!  
Giá» mÃ¬nh chuyá»ƒn sang **Má»¥c 3: Kernel Design** nhÃ©.

---

# ğŸ§© Má»¥c 3: Kernel Design (Thiáº¿t káº¿ hÃ m Kernel)

**Ã tÆ°á»Ÿng chÃ­nh:**  
Trong Gaussian Process (GPs), **kernel function** (cÃ²n gá»i lÃ  **covariance function**) Ä‘á»‹nh nghÄ©a Ä‘á»™ tÆ°Æ¡ng quan giá»¯a hai Ä‘iá»ƒm báº¥t ká»³ $ x $ vÃ  $ x' $.  
NÃ³ cho GP kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a nhiá»u dáº¡ng má»‘i quan há»‡ khÃ¡c nhau nhÆ°: tuyáº¿n tÃ­nh, phi tuyáº¿n, tuáº§n hoÃ n,...

---

## ğŸŒŸ CÃ¡c bÆ°á»›c cáº§n náº¯m:

1. **Kernel lÃ  gÃ¬?**
   - Kernel $ k(x, x') $ Ä‘o "má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng" giá»¯a hai Ä‘iá»ƒm $ x $ vÃ  $ x' $.
   - Káº¿t quáº£ $ k(x, x') $ lÃ  má»™t sá»‘ thá»±c.

2. **TÃ­nh cháº¥t cá»§a kernel:**
   - Pháº£i **Ä‘á»‘i xá»©ng**: $ k(x, x') = k(x', x) $
   - Pháº£i sinh ra **ma tráº­n hiá»‡p phÆ°Æ¡ng sai** (covariance matrix) **dÆ°Æ¡ng bÃ¡n xÃ¡c Ä‘á»‹nh** (positive semi-definite - PSD).

3. **Má»™t sá»‘ kernel cÆ¡ báº£n:**

   - **Linear Kernel**:
     $
     k(x, x') = x^\top x'
     $
     â‡’ Giá»‘ng nhÆ° mÃ´ hÃ¬nh tuyáº¿n tÃ­nh.

   - **RBF (Radial Basis Function) Kernel / Gaussian Kernel**:
     $
     k(x, x') = \exp\left( -\frac{||x - x'||^2}{2l^2} \right)
     $
     - $ l $ lÃ  tham sá»‘ Ä‘iá»u chá»‰nh má»©c Ä‘á»™ "má»‹n" (smoothness).

   - **Polynomial Kernel**:
     $
     k(x, x') = (x^\top x' + c)^d
     $
     - $ c $ lÃ  há»‡ sá»‘ Ä‘iá»u chá»‰nh, $ d $ lÃ  báº­c Ä‘a thá»©c.

   - **Periodic Kernel**:
     $
     k(x, x') = \exp\left( -\frac{2 \sin^2(\pi (x - x') / p)}{l^2} \right)
     $
     - $ p $ lÃ  chu ká»³.

4. **Kernel tá»± xÃ¢y dá»±ng (Custom Kernel):**
   - Báº¡n cÃ³ thá»ƒ káº¿t há»£p cá»™ng/trá»«/nhÃ¢n cÃ¡c kernel Ä‘á»ƒ táº¡o kernel má»›i!
   - VÃ­ dá»¥:
     $
     k_{\text{new}}(x, x') = k_1(x, x') + k_2(x, x')
     $
     hoáº·c
     $
     k_{\text{new}}(x, x') = k_1(x, x') \times k_2(x, x')
     $

---

## ğŸ§  Hiá»ƒu trá»±c giÃ¡c:
- Náº¿u $ k(x, x') $ lá»›n â‡’ $ x $ vÃ  $ x' $ ráº¥t giá»‘ng nhau â‡’ giÃ¡ trá»‹ $ f(x) $ vÃ  $ f(x') $ cÅ©ng gáº§n nhau.
- Náº¿u $ k(x, x') $ nhá» â‡’ $ x $ vÃ  $ x' $ Ã­t liÃªn quan â‡’ giÃ¡ trá»‹ $ f(x) $ vÃ  $ f(x') $ cÃ³ thá»ƒ khÃ¡c xa.

---

## ğŸ“ Má»™t bÃ i táº­p nhá» (lÃ m tay):

Giáº£ sá»­ dÃ¹ng **RBF Kernel** vá»›i $ l=1 $:

$
k(x, x') = \exp\left( -\frac{||x-x'||^2}{2} \right)
$

TÃ­nh $ k(2, 3) $.

**Giáº£i:**
$
||2 - 3||^2 = 1^2 = 1
$
$
k(2, 3) = \exp\left( -\frac{1}{2} \right) = \exp(-0.5) \approx 0.6065
$

Váº­y: **$ k(2,3) \approx 0.6065 $**.

---

Ráº¥t gá»n gÃ ng vÃ  chuyÃªn nghiá»‡p luÃ´n! ğŸ”¥  
BÃ¢y giá» ta Ä‘Ã£ hoÃ n thÃ nh:

- Giai Ä‘oáº¡n 1: **Giá»›i thiá»‡u**
- Giai Ä‘oáº¡n 2: **ToÃ¡n há»c ná»n táº£ng**
- Giai Ä‘oáº¡n 3: **Kernel Design**

---

# ğŸ¯ Tiáº¿p theo sáº½ lÃ  **Má»¥c 4: Implement GP cÆ¡ báº£n (Regression)**

### Cá»¥ thá»ƒ trong má»¥c nÃ y, chÃºng ta sáº½:
1. **Viáº¿t code** cho Gaussian Process **Regression** (báº£n cá»±c ká»³ cÆ¡ báº£n).
2. Tá»± tay implement cÃ¡c bÆ°á»›c:
   - TÃ­nh ma tráº­n Kernel $ K(X, X) $, $ K(X, X_*) $, $ K(X_*, X_*) $
   - TÃ­nh toÃ¡n:
     - **Posterior mean**: $ \mu_* = K(X_*, X) K(X, X)^{-1} y $
     - **Posterior covariance**: $ \Sigma_* = K(X_*, X_*) - K(X_*, X) K(X, X)^{-1} K(X, X_*) $
3. **Táº¡o má»™t bÃ i toÃ¡n Regression Ä‘Æ¡n giáº£n**, vÃ­ dá»¥:
   - $ y = \sin(x) $ trÃªn khoáº£ng $ [0, 5] $ vá»›i vÃ i Ä‘iá»ƒm noise.
4. **Plot** ra:
   - Predictive mean
   - Predictive variance (Â±2Ïƒ)

---

# ğŸ§  Má»¥c tiÃªu sau bÆ°á»›c nÃ y:
- Báº¡n hiá»ƒu rÃµ **cÆ¡ cháº¿ dá»± Ä‘oÃ¡n** cá»§a Gaussian Process Regression.
- Báº¡n tá»± tay build Ä‘Æ°á»£c má»™t GP nhá», **khÃ´ng dÃ¹ng thÆ° viá»‡n nhÆ° sklearn hay GPyTorch**.

---

# ğŸ“‹ Checklist chi tiáº¿t cho Má»¥c 4:
| STT | CÃ´ng viá»‡c | Tráº¡ng thÃ¡i |
|:---:|:---|:---:|
| 1 | Viáº¿t hÃ m RBF Kernel | â¬œ |
| 2 | TÃ­nh $ K(X,X) $, $ K(X,X_*) $, $ K(X_*,X_*) $ | â¬œ |
| 3 | TÃ­nh Posterior Mean vÃ  Covariance | â¬œ |
| 4 | Viáº¿t function `predict(X_train, y_train, X_test)` | â¬œ |
| 5 | Táº¡o dataset toy $ y = \sin(x) $ | â¬œ |
| 6 | Plot káº¿t quáº£ (mean Â± 2Ïƒ) | â¬œ |

---

Báº¡n cÃ³ muá»‘n mÃ¬nh dáº«n dáº¯t tá»«ng bÆ°á»›c má»™t ngay bÃ¢y giá» khÃ´ng?  
ğŸ‘‰ Náº¿u Ä‘á»“ng Ã½, mÃ¬nh sáº½ báº¯t Ä‘áº§u báº±ng viá»‡c viáº¿t **hÃ m RBF Kernel** trÆ°á»›c nhÃ©. ğŸš€  
(hoáº·c náº¿u báº¡n muá»‘n Ä‘iá»u chá»‰nh thá»© tá»± thÃ¬ cÅ©ng Ä‘Æ°á»£c nha!)

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>