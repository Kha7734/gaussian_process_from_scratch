{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 10, 28, 28]), torch.Size([1000, 2]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "num_bags = 1000\n",
    "instances_per_bag = 10\n",
    "label_digit = 7  # digit to detect\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Prepare the data\n",
    "def create_mil_mnist_bags(dataset, num_bags=1000, instances_per_bag=10, target_digit=7):\n",
    "    bags = []\n",
    "    labels = []  # Two binary labels per bag\n",
    "\n",
    "    data = dataset.data\n",
    "    targets = dataset.targets\n",
    "\n",
    "    for _ in range(num_bags):\n",
    "        indices = np.random.choice(len(dataset), instances_per_bag, replace=False)\n",
    "        images = data[indices]\n",
    "        digits = targets[indices]\n",
    "\n",
    "        # First label: at least one image of the target digit\n",
    "        label_1 = (digits == target_digit).any().item()\n",
    "        # Second label: more than one image of the target digit\n",
    "        label_2 = (digits == target_digit).sum().item() > 1\n",
    "\n",
    "        bags.append(images)\n",
    "        labels.append(torch.tensor([label_1, label_2], dtype=torch.float32))\n",
    "\n",
    "    bags = torch.stack(bags)  # [num_bags, instances_per_bag, H, W]\n",
    "    labels = torch.stack(labels)  # [num_bags, 2]\n",
    "\n",
    "    return bags, labels\n",
    "\n",
    "# Generate MIL-style bags\n",
    "mil_bags, mil_labels = create_mil_mnist_bags(mnist_dataset, num_bags, instances_per_bag, label_digit)\n",
    "mil_bags.shape, mil_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "  def __init__(self, input_dim):\n",
    "    super(AttentionLayer, self).__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.attention_weights = nn.Parameter(torch.randn(input_dim, 1))\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    self.fc = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # x: [batch_size, num_instances, input_dim]\n",
    "    batch_size, num_instances, _ = x.size()\n",
    "    x_flat = x.view(batch_size * num_instances, self.input_dim)\n",
    "    \n",
    "    # Compute attention scores\n",
    "    attention_scores = torch.matmul(x_flat, self.attention_weights).view(batch_size, num_instances)\n",
    "    \n",
    "    # Apply softmax to get attention weights\n",
    "    attention_weights = self.softmax(attention_scores)\n",
    "    \n",
    "    # Weighted sum of instances\n",
    "    weighted_sum = torch.bmm(attention_weights.unsqueeze(1), x).squeeze(1)\n",
    "    \n",
    "    # Pass through a linear layer\n",
    "    output = self.fc(weighted_sum)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rbf_kernel(nn.Module):\n",
    "    def __init__(self, input_dim, lengthscale_init=1.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        # Use one lengthscale per dimension (ARD - Automatic Relevance Determination)\n",
    "        self.log_lengthscale = nn.Parameter(torch.log(torch.ones(input_dim) * lengthscale_init))\n",
    "\n",
    "    def forward(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Compute RBF (Gaussian) kernel matrix between X1 and X2 using ARD lengthscales.\n",
    "        Args:\n",
    "            X1: Tensor of shape (N1, D)\n",
    "            X2: Tensor of shape (N2, D)\n",
    "        Returns:\n",
    "            Kernel matrix of shape (N1, N2)\n",
    "        \"\"\"\n",
    "        # Ensure input is 2D\n",
    "        if X1.ndimension() == 1:\n",
    "            X1 = X1.unsqueeze(0)\n",
    "        if X2.ndimension() == 1:\n",
    "            X2 = X2.unsqueeze(0)\n",
    "\n",
    "        # Scale by lengthscale (ARD: each dimension can have a different scale)\n",
    "        X1_scaled = X1 / self.log_lengthscale.exp()\n",
    "        X2_scaled = X2 / self.log_lengthscale.exp()\n",
    "\n",
    "        # Compute squared Euclidean distance\n",
    "        sqdist = torch.cdist(X1_scaled, X2_scaled, p=2).pow(2)\n",
    "\n",
    "        # Compute RBF\n",
    "        return torch.exp(-0.5 * sqdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVGP Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputSVGP(nn.Module):\n",
    "    def __init__(self, input_dim, num_tasks, num_inducing):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_tasks = num_tasks\n",
    "        self.num_inducing = num_inducing\n",
    "\n",
    "        # Shared inducing points Z\n",
    "        self.Z = nn.Parameter(torch.randn(num_inducing, input_dim))\n",
    "\n",
    "        # Variational parameters\n",
    "        self.m = nn.Parameter(torch.zeros(num_inducing))  # Mean of variational distribution\n",
    "        self.L = nn.Parameter(torch.eye(num_inducing))  # Lower-triangular Cholesky of S\n",
    "\n",
    "        # Base kernel\n",
    "        self.kernel = rbf_kernel(input_dim)\n",
    "\n",
    "        # Coregionalization matrix B (T x T)\n",
    "        self.B = nn.Parameter(torch.eye(num_tasks))\n",
    "        \n",
    "        # Register buffer for device tracking\n",
    "        self.register_buffer('dummy', torch.zeros(1))\n",
    "\n",
    "    def compute_coregionalized_kernel(self, X1, T1, X2, T2):\n",
    "        \"\"\"\n",
    "        Coregionalized kernel: K((x,t), (x',t')) = k(x,x') * B[t,t']\n",
    "        \"\"\"\n",
    "        # Get the device from model parameters\n",
    "        device = self.dummy.device\n",
    "        \n",
    "        # Ensure T1 and T2 are on the correct device\n",
    "        if isinstance(T1, torch.Tensor):\n",
    "            T1 = T1.to(device)\n",
    "        else:\n",
    "            T1 = torch.tensor(T1, dtype=torch.long, device=device)\n",
    "            \n",
    "        if isinstance(T2, torch.Tensor):\n",
    "            T2 = T2.to(device)\n",
    "        else:\n",
    "            T2 = torch.tensor(T2, dtype=torch.long, device=device)\n",
    "            \n",
    "        k_base = self.kernel(X1, X2)  # [N, M]\n",
    "        B_selected = self.B[T1][:, T2]  # [N, M]\n",
    "        return k_base * B_selected\n",
    "    \n",
    "    def forward(self, X, T, Y, full_n):\n",
    "        \"\"\"\n",
    "        X: [B, D], input features\n",
    "        T: [B], task indices\n",
    "        Y: [B], binary labels (0 or 1)\n",
    "        full_n: total number of training samples (for scaling ELBO)\n",
    "        \"\"\"\n",
    "        # Get the device from model parameters\n",
    "        device = self.dummy.device\n",
    "        \n",
    "        B = X.shape[0]  # batch size\n",
    "        M = self.num_inducing\n",
    "\n",
    "        # Compute kernel matrices\n",
    "        Kxz = self.compute_coregionalized_kernel(X, T, self.Z, torch.zeros(M, dtype=torch.long, device=device))  # [B, M]\n",
    "        Kzz = self.compute_coregionalized_kernel(self.Z, torch.zeros(M, dtype=torch.long, device=device),\n",
    "                                                 self.Z, torch.zeros(M, dtype=torch.long, device=device)) + 1e-6 * torch.eye(M, device=device)\n",
    "\n",
    "        # Compute predictive mean and variance of q(f)\n",
    "        Lzz = torch.linalg.cholesky(Kzz)\n",
    "        Kzz_inv = torch.cholesky_inverse(Lzz)\n",
    "\n",
    "        S = self.L @ self.L.T  # Ensure positive-definite\n",
    "\n",
    "        mean_f = Kxz @ Kzz_inv @ self.m  # [B]\n",
    "        cov_f = (Kxz @ Kzz_inv @ S @ Kzz_inv @ Kxz.T).diag()  # [B]\n",
    "        std_f = torch.sqrt(cov_f + 1e-6)\n",
    "\n",
    "        # Monte Carlo sampling (approximation of latent function)\n",
    "        eps = torch.randn_like(mean_f)\n",
    "        f_sample = mean_f + std_f * eps\n",
    "\n",
    "        # Sigmoid for binary classification\n",
    "        prob = torch.sigmoid(f_sample)\n",
    "\n",
    "        # Log likelihood term (binary cross-entropy for classification)\n",
    "        log_lik = Y * F.logsigmoid(f_sample) + (1 - Y) * F.logsigmoid(-f_sample) # Log-likelihood of Bernoulli\n",
    "        log_lik_term = (full_n / B) * log_lik.sum()\n",
    "\n",
    "        # KL[q(u) || p(u)] (variational KL divergence)\n",
    "        KL = 0.5 * (\n",
    "            torch.trace(Kzz_inv @ S) +\n",
    "            self.m @ Kzz_inv @ self.m -\n",
    "            M +\n",
    "            torch.logdet(Kzz) - torch.logdet(S + 1e-6 * torch.eye(M, device=device))\n",
    "        )\n",
    "\n",
    "        elbo = log_lik_term - KL\n",
    "        return -elbo  # minimize negative ELBO\n",
    "\n",
    "    def predict(self, X_test, T_test):\n",
    "        \"\"\"\n",
    "        X_test: [B_test, D], test input features\n",
    "        T_test: [B_test], task indices for the test set\n",
    "        \"\"\"\n",
    "        # Get the device from model parameters\n",
    "        device = self.dummy.device\n",
    "        \n",
    "        self.eval()\n",
    "        B_test = X_test.shape[0]  # batch size of test points\n",
    "        M = self.num_inducing\n",
    "\n",
    "        # Compute kernel between test points and inducing points\n",
    "        Kxz_test = self.compute_coregionalized_kernel(X_test, T_test, self.Z, torch.zeros(M, dtype=torch.long, device=device))  # [B_test, M]\n",
    "\n",
    "        # Compute kernel between inducing points\n",
    "        Kzz = self.compute_coregionalized_kernel(self.Z, torch.zeros(M, dtype=torch.long, device=device),\n",
    "                                                 self.Z, torch.zeros(M, dtype=torch.long, device=device)) + 1e-6 * torch.eye(M, device=device)\n",
    "\n",
    "        # Cholesky decomposition of Kzz\n",
    "        Lzz = torch.linalg.cholesky(Kzz)\n",
    "        Kzz_inv = torch.cholesky_inverse(Lzz)\n",
    "\n",
    "        # Compute the posterior mean: Kxz_test * Kzz_inv * m\n",
    "        mean_f_test = Kxz_test @ Kzz_inv @ self.m  # [B_test]\n",
    "\n",
    "        # Compute the posterior covariance: Kxz_test * Kzz_inv * S * Kzz_inv * Kxz_test.T\n",
    "        S = self.L @ self.L.T  # Ensure positive-definite\n",
    "        cov_f_test = (Kxz_test @ Kzz_inv @ S @ Kzz_inv @ Kxz_test.T).diag()  # [B_test]\n",
    "\n",
    "        # Compute the posterior standard deviation\n",
    "        std_f_test = torch.sqrt(cov_f_test + 1e-6)\n",
    "\n",
    "        # Apply sigmoid to get probabilities\n",
    "        prob_test = torch.sigmoid(mean_f_test)\n",
    "\n",
    "        return prob_test, std_f_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILMNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, bags, labels):\n",
    "        \"\"\"\n",
    "        A simple dataset class for MIL MNIST data\n",
    "        \n",
    "        Parameters:\n",
    "        bags: [num_bags, instances_per_bag, H, W] - Bags of MNIST images\n",
    "        labels: [num_bags, num_tasks] - Labels for each bag and task\n",
    "        \"\"\"\n",
    "        self.bags = bags\n",
    "        self.labels = labels\n",
    "        self.num_bags = bags.shape[0]\n",
    "        self.num_tasks = labels.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return total number of bag-task pairs\n",
    "        return self.num_bags * self.num_tasks\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert idx to bag_idx and task_idx\n",
    "        bag_idx = idx // self.num_tasks\n",
    "        task_idx = idx % self.num_tasks\n",
    "        \n",
    "        # Get the bag\n",
    "        bag = self.bags[bag_idx]  # [instances_per_bag, H, W]\n",
    "        \n",
    "        # Get the label for this task\n",
    "        label = self.labels[bag_idx, task_idx]\n",
    "        \n",
    "        return bag, torch.tensor(task_idx, dtype=torch.long), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, num_instances, feature_dim]\n",
    "        attention_weights = self.attention(x)  # [batch_size, num_instances, 1]\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)  # Normalize weights across instances\n",
    "        \n",
    "        # Weighted sum of instance features\n",
    "        weighted_features = torch.sum(x * attention_weights, dim=1)  # [batch_size, feature_dim]\n",
    "        \n",
    "        return weighted_features, attention_weights\n",
    "\n",
    "class MIL_SVGP(nn.Module):\n",
    "    def __init__(self, num_classes, feature_dim=512, num_inducing=50, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extractor (ResNet18)\n",
    "        self.feature_extractor = resnet18(pretrained=pretrained)\n",
    "        # Modify the first conv layer to accept grayscale images (1 channel)\n",
    "        self.feature_extractor.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Remove the final classification layer\n",
    "        self.feature_dim = feature_dim\n",
    "        self.feature_extractor = nn.Sequential(*list(self.feature_extractor.children())[:-1])\n",
    "        \n",
    "        # Attention mechanism for instance aggregation\n",
    "        self.attention = AttentionLayer(feature_dim)\n",
    "        \n",
    "        # Final classifier\n",
    "        self.classifier = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "        # Linear layer \n",
    "        self.linear_layer = nn.Linear(feature_dim, 8)\n",
    "        \n",
    "        # SVGP model for each task/class\n",
    "        self.svgp = MultiOutputSVGP(\n",
    "            input_dim=8,\n",
    "            num_tasks=num_classes,\n",
    "            num_inducing=num_inducing\n",
    "        )\n",
    "        \n",
    "        # Register a buffer to track device\n",
    "        self.register_buffer('dummy', torch.zeros(1))\n",
    "        \n",
    "    def extract_instance_features(self, x):\n",
    "        \"\"\"\n",
    "        Extract features from individual instances\n",
    "        \n",
    "        Parameters:\n",
    "        x: [batch_size, num_instances, channels, height, width]\n",
    "        \n",
    "        Returns:\n",
    "        features: [batch_size, num_instances, feature_dim]\n",
    "        \"\"\"\n",
    "        batch_size, num_instances = x.shape[0], x.shape[1]\n",
    "        \n",
    "        # Reshape to process all instances at once\n",
    "        x_reshaped = x.view(batch_size * num_instances, *x.shape[2:])\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x_reshaped)\n",
    "        features = features.view(features.size(0), -1)  # Flatten spatial dimensions\n",
    "        \n",
    "        # Reshape back to [batch_size, num_instances, feature_dim]\n",
    "        features = features.view(batch_size, num_instances, -1)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def forward(self, x, task_indices, labels=None, full_n=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \n",
    "        Parameters:\n",
    "        x: [batch_size, num_instances, channels, height, width] - Bag of instances\n",
    "        task_indices: [batch_size] - Task indices for each bag\n",
    "        labels: [batch_size] - Labels for each bag (optional, for training)\n",
    "        full_n: Total number of training samples (optional, for ELBO scaling)\n",
    "        \n",
    "        Returns:\n",
    "        logits: [batch_size, num_classes] - Classification logits\n",
    "        loss: Scalar - SVGP loss (if labels and full_n are provided)\n",
    "        \"\"\"\n",
    "        device = self.dummy.device\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Ensure x is properly formatted\n",
    "        if len(x.shape) == 4:  # [batch_size, num_instances, height, width]\n",
    "            # Add channel dimension for grayscale\n",
    "            x = x.unsqueeze(2)  # [batch_size, num_instances, 1, height, width]\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        x = x.float() / 255.0\n",
    "        \n",
    "        # Extract features from each instance in each bag\n",
    "        instance_features = self.extract_instance_features(x)  # [batch_size, num_instances, feature_dim]\n",
    "        \n",
    "        # Aggregate instance features using attention\n",
    "        bag_features, attention_weights = self.attention(instance_features)  # [batch_size, feature_dim]\n",
    "        \n",
    "        # Get classification logits\n",
    "        logits = self.classifier(bag_features)  # [batch_size, num_classes]\n",
    "        \n",
    "        # Calculate SVGP loss if in training mode\n",
    "        loss = None\n",
    "        if labels is not None and full_n is not None:\n",
    "            bag_features = self.linear_layer(bag_features)  # [batch_size, 8]\n",
    "            loss = self.svgp(bag_features, task_indices, labels, full_n)\n",
    "        \n",
    "        return logits, loss, bag_features, attention_weights\n",
    "    \n",
    "    def predict(self, x, task_indices):\n",
    "        \"\"\"\n",
    "        Make predictions for test data\n",
    "        \n",
    "        Parameters:\n",
    "        x: [batch_size, num_instances, channels, height, width] - Bag of instances\n",
    "        task_indices: [batch_size] - Task indices for each bag\n",
    "        \n",
    "        Returns:\n",
    "        probs: [batch_size] - Predicted probabilities\n",
    "        stds: [batch_size] - Uncertainty estimates\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Ensure x is properly formatted\n",
    "        if len(x.shape) == 4:  # [batch_size, num_instances, height, width]\n",
    "            # Add channel dimension for grayscale\n",
    "            x = x.unsqueeze(2)  # [batch_size, num_instances, 1, height, width]\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        x = x.float() / 255.0\n",
    "        \n",
    "        # Extract and aggregate features\n",
    "        with torch.no_grad():\n",
    "            instance_features = self.extract_instance_features(x)\n",
    "            bag_features, _ = self.attention(instance_features)\n",
    "            \n",
    "            # Get SVGP predictions\n",
    "            probs, stds = self.svgp.predict(bag_features, task_indices)\n",
    "        \n",
    "        return probs, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Train bags shape: torch.Size([800, 10, 28, 28]), Train labels shape: torch.Size([800, 2])\n",
      "Test bags shape: torch.Size([200, 10, 28, 28]), Test labels shape: torch.Size([200, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hskha23/miniconda3/envs/tf/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 555.3259\n",
      "Epoch 2/20, Loss: 554.7806\n",
      "Epoch 3/20, Loss: 554.6634\n",
      "Epoch 4/20, Loss: 554.6228\n",
      "Epoch 5/20, Loss: 554.5673\n",
      "Epoch 6/20, Loss: 554.5479\n",
      "Epoch 7/20, Loss: 554.5397\n",
      "Epoch 8/20, Loss: 554.5405\n",
      "Epoch 9/20, Loss: 554.5300\n",
      "Epoch 10/20, Loss: 554.5286\n",
      "Epoch 11/20, Loss: 554.5289\n",
      "Epoch 12/20, Loss: 554.5209\n",
      "Epoch 13/20, Loss: 554.5324\n",
      "Epoch 14/20, Loss: 554.5168\n",
      "Epoch 15/20, Loss: 554.5343\n",
      "Epoch 16/20, Loss: 554.5167\n",
      "Epoch 17/20, Loss: 554.5370\n",
      "Epoch 18/20, Loss: 554.5519\n",
      "Epoch 19/20, Loss: 554.5300\n",
      "Epoch 20/20, Loss: 554.5347\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Split data\n",
    "indices = np.arange(len(mil_bags))\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_bags = mil_bags[train_indices]\n",
    "train_labels = mil_labels[train_indices]\n",
    "test_bags = mil_bags[test_indices]\n",
    "test_labels = mil_labels[test_indices]\n",
    "\n",
    "print(f\"Train bags shape: {train_bags.shape}, Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test bags shape: {test_bags.shape}, Test labels shape: {test_labels.shape}\")\n",
    "\n",
    "# Create a simple dataset class that returns bags, task indices, and labels\n",
    "class MILDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, bags, labels):\n",
    "        self.bags = bags\n",
    "        self.labels = labels\n",
    "        self.num_bags = bags.shape[0]\n",
    "        self.num_tasks = labels.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_bags * self.num_tasks\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        bag_idx = idx // self.num_tasks\n",
    "        task_idx = idx % self.num_tasks\n",
    "        \n",
    "        bag = self.bags[bag_idx]\n",
    "        label_index = self.labels[bag_idx, task_idx]\n",
    "        labels = self.labels[bag_idx]\n",
    "        \n",
    "        return bag, torch.tensor(task_idx, dtype=torch.long), label_index, labels\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MILDataset(train_bags, train_labels)\n",
    "test_dataset = MILDataset(test_bags, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Initialize the integrated MIL-SVGP model\n",
    "model = MIL_SVGP(\n",
    "    num_classes=2,  # Binary classification for each task\n",
    "    feature_dim=512,  # ResNet18 feature dimension\n",
    "    num_inducing=50,\n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for bags, task_indices, labels_index, labels in train_loader:\n",
    "        # Move data to device\n",
    "        bags = bags.to(device)\n",
    "        task_indices = task_indices.to(device)\n",
    "        labels_index = labels_index.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logit, loss, _, _ = model(bags, task_indices, labels_index, len(train_dataset))\n",
    "        # print(f'Shape of labels: {labels.shape}')\n",
    "        loss = bce_loss(logit, labels) * 0.5 + loss * 0.5\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình trên tập kiểm tra sau khi huấn luyện xong\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_tasks, batch_labels_index, batch_labels in test_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        batch_tasks = batch_tasks.to(device)\n",
    "        \n",
    "        # Dự đoán xác suất cho mỗi mẫu trong batch\n",
    "        # probs, _ = model.predict(batch_features, batch_tasks)\n",
    "        logits, _, _, _ = model(batch_features, batch_tasks)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = probs.cpu()\n",
    "        \n",
    "        # Chuyển xác suất thành nhãn dự đoán (ngưỡng 0.5)\n",
    "        preds = (probs >= 0.5).float()\n",
    "        \n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(batch_labels.cpu())\n",
    "\n",
    "# Gộp các batch lại\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "# precision = precision_score(all_labels, all_preds)\n",
    "# recall = recall_score(all_labels, all_preds)\n",
    "# f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
